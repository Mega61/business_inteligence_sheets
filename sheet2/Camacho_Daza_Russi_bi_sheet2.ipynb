{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 1 (4 points)***\n",
    "1. Under what conditions will the covariance matrix Σ be identical to the correlation matrix? What can you say about the variances of the variables?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random variable results are normalized before being tabulated.\n",
    "- The standard deviation of both variables needs to be 1 on the covariance matrix leading diagonal.\n",
    "- PMFs/PDFs have to display approachable similarity to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Covariances and Correlation after Normalization Techniques. Robustness of Normalization towards linear feature transformations. \n",
    "\n",
    "Let D∈Rn×d be some dataset. Suppose that we have, for each column Xj,  a transfor-maton fj:R→Rthat will modify the values in thej-th column. The result of applying these functions will be a new dataset (matrix) ̃D∈Rn×d with  ̃Di,j=fj(Di,j). Note that we could have fj(x)=x if we do not want to change values in thej-th  column.\n",
    "\n",
    "Such  a function fj is  said to be affine if it is of the form fj(x) =ax+b for some a, b ∈ R.\n",
    "\n",
    "a) Give an example for a transformation (may be affine or not) that affects the covariance, i.e., the covariance matrix of ̃D is different from that in D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f_{j}(x) = 0$ for all $j$. Then $cov(x,y) = 0$ for any two random variable samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now show that ̃μj=ajˆμj+bj and that ̃σij=aiajˆσi jfor any affine transformation ,where ̃μ jdenotes the empirical mean of attribute Xj of ̃D, and ̃σij is the empirical covariance of attributes Xi and Xj in ̃D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $f_j(x)$ is affine with $f_j(x) = a_j \\cdot x + b_j$.\n",
    "Then:\n",
    "$$\\^{\\~{\\mu_j}} = f_j(\\^{\\mu})$$\n",
    "$$= f_j(E[\\^{\\~{X_j}}])$$\n",
    "$$= E[f_j(\\^{\\~{X_j}})]$$\n",
    "$$= E[a_j \\cdot \\^{X_j} + b_j]$$\n",
    "$$= a_j \\cdot E[\\^{X_j}] + b_j$$\n",
    "$$= a_j \\cdot \\^{\\mu} + b_j$$\n",
    "We also have:\n",
    "$$\\^{\\~{\\sigma_{ij}}} = E[(\\^{\\~{X_i}}-\\^{\\~{\\mu}})(\\^{\\~{X_j}}-\\^{\\~{\\mu}})]$$\n",
    "$$= E[\\^{\\~{X_i}} \\cdot \\^{\\~{X_j}}] - E[\\^{\\~{\\mu_i}}] \\cdot E[\\^{\\~{\\mu_j}}]$$\n",
    "$$= E[(a_i \\cdot \\^{X_i} + b_i)(a_j \\cdot \\^{X_j} + b_j)] - E[a_i \\cdot \\^{\\mu_i} + b_i] \\cdot E[a_j \\cdot \\^{X_j} + b_j]$$\n",
    "$$= E[a_i \\cdot a_j \\cdot \\^{X_i} \\cdot \\^{X_j} + a_i \\cdot \\^{X_i} \\cdot b_j + a_j \\cdot \\^{X_j} \\cdot b_i + b_i \\cdot b_j] - (a_i \\cdot E[\\^{\\mu_i}] + b_i) \\cdot (a_j \\cdot E[\\^{\\mu_j}] + b_j)$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] + a_i \\cdot E[\\^{X_i}] \\cdot b_j + a_j \\cdot E[\\^{X_j}] \\cdot b_i + b_i \\cdot b_j - (a_i \\cdot \\^{\\mu_i} + b_i) \\cdot (a_j \\cdot \\^{mu_j} + b_j)$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] + a_i \\cdot E[\\^{X_i}] \\cdot b_j + a_j \\cdot E[\\^{X_j}] \\cdot b_i + b_i \\cdot b_j - a_i \\cdot \\^{\\mu_i}\\cdot b_j - a_j \\cdot \\^{\\mu_j} \\cdot b_i - b_i \\cdot b_j - a_i \\cdot a_j \\cdot \\^{\\mu_i} \\cdot \\^{\\mu_j}$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] - a_i \\cdot a_j \\cdot \\^{\\mu_i} \\cdot \\^{\\mu_j}$$\n",
    "$$= a_i \\cdot a_j (E[\\^{X_i} \\cdot \\^{X_j}] - \\^{\\mu_i} \\cdot \\^{\\mu_j})$$\n",
    "$$= a_i \\cdot a_j \\cdot \\^{\\sigma_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Now let ̃ρij be the correlation between Xi and Xj in ̃D. Show that ̃ρij= ˆρij. State in your own words what this property means (one sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "$$\\^{\\~{\\rho_{12}}} = \\frac{\\^{\\~{\\sigma_{12}}}}{\\^{\\~{\\sigma_1}} \\cdot \\^{\\~{\\sigma_2}}}$$\n",
    "$$= \\frac{\\^{\\~{\\sigma_{12}}}}{\\sqrt{\\^{\\~{\\sigma_1^2}} \\cdot \\^{\\~{\\sigma_2^2}}}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{\\sqrt{(a_i^2 \\cdot \\^{\\sigma_1^2}) \\cdot (a_j^2 \\cdot \\^{\\sigma_2^2})}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{\\sqrt{a_i^2 \\cdot a_j^2 \\cdot \\^{\\sigma_1^2} \\cdot \\^{\\sigma_2^2}}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{a_i \\cdot a_j \\sqrt{\\^{\\sigma_1^2 \\cdot \\sigma_2^2}}}$$\n",
    "$$= \\frac{\\^{\\sigma_{12}}}{\\sqrt{\\^{\\sigma_1^2 \\cdot \\sigma_2^2}}}$$\n",
    "$$= \\frac{\\^{\\sigma_{12}}}{\\^{\\sigma_1} \\cdot \\^{\\sigma_2}}$$\n",
    "$$= \\^{\\rho_{12}}$$\n",
    "\n",
    "This means that when any affine function is applied to a set of columns from a matrix, its covariance matrix will not change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2 (4 Points)***\n",
    "\n",
    "Use only one notebook for the following exercises. Answer the ques-tions in separate markdowncells under the corresponding code. \n",
    "\n",
    "Do notuse any lirbary’s function to compute the mean, cov or cor (like np.cov) within thisexercise.\n",
    "\n",
    "Make sure that your functions have exactly the required name (in order to make them appli-cable to unit tests).\n",
    "\n",
    "1. Write a function getStats(A) that outputs (i) the sample mean, the sample covariance matrix, and (iii) the correlation matrix for a given 2-dimensional numpy arrayA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5.843, 3.054, 3.759, 1.199]), array([[ 0.681, -0.039,  1.265,  0.513, -0.039,  0.187, -0.32 , -0.117,\n",
      "         1.265, -0.32 ,  3.092,  1.288,  0.513, -0.117,  1.288,  0.579]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "dfIrisTest = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A = dfIrisTest.values[:, 0:4].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "def covariance_matrix(x1, x2, sample_mean_x1, sample_mean_x2):\n",
    "    x_1 = [i - sample_mean_x1 for i in x1]\n",
    "    x_2 = [i - sample_mean_x2 for i in x2]\n",
    "    covariance12 = sum([x_2[i]*x_1[i] for i in range(len(x1))])/len(x1)\n",
    "    return covariance12\n",
    "\n",
    "def getStats(A):\n",
    "    vector_sample_mean = []\n",
    "    vector_covariance = np.array([[]])\n",
    "    list_cov = np.array([[]])\n",
    "    cov_sum=[]\n",
    "    for j in range(np.size(A, 1)):\n",
    "        sample_mean = 0\n",
    "        for i in range(np.size(A, 0)):\n",
    "            sample_mean += A[i, j]/np.size(A, 0)\n",
    "        vector_sample_mean += [sample_mean]\n",
    "\n",
    "    for j in range (len(vector_sample_mean)):\n",
    "        list_cov = np.array([[]])\n",
    "        for i in range (len(vector_sample_mean)):\n",
    "            cov1 = np.array([A[:,j]-vector_sample_mean[j]])\n",
    "            cov2 = (np.array([A[:,i]-vector_sample_mean[j]]))\n",
    "            covariance = ((np.dot(cov2, cov1.T)))/len(A[:, i])\n",
    "            #cov_sum += np.sum(covariance, axis=0)\n",
    "            #list_cov = np.vstack([list_cov, covariance])\n",
    "            list_cov = np.column_stack([list_cov, covariance])\n",
    "            #print(list_cov)\n",
    "        vector_covariance =  np.column_stack([vector_covariance, list_cov])\n",
    "    #vector_covariance = np.empty((len(vector_sample_mean), len(vector_sample_mean)))\n",
    "    #vector_covariance = [[1,2,3,4]]\n",
    "    #print(vector_covariance)\n",
    "    #for j in range(len(vector_sample_mean)):\n",
    "    #    list_cov = []\n",
    "    #    for k in range(len(vector_sample_mean)):\n",
    "    #        covariance = covariance_matrix(A[:, j], A[:, k], vector_sample_mean[j], vector_sample_mean[k])\n",
    "    #        list_cov = np.append(list_cov, [np.round(covariance,3)], 0)\n",
    "    #        print(list_cov)\n",
    "    #vector_covariance = np.vstack([vector_covariance, list_cov])\n",
    "    #print((len(vector_sample_mean)))\n",
    "    #if j < (len(vector_sample_mean)-1):\n",
    "    #     print('gonrreas')\n",
    "    #     #vector_covariance = np.insert(vector_covariance, [j,k], list_cov)\n",
    "    #     vector_covariance = np.vstack([vector_covariance, list_cov])\n",
    "    #     #vector_covariance = np.append(vector_covariance, list_cov, 0)\n",
    "    # else:\n",
    "    #     print('else')\n",
    "       \n",
    "\n",
    "    return np.round(vector_sample_mean,3), np.round(vector_covariance, 3)\n",
    "\n",
    "#np.array([[ 1., -0.109, 0.872, 0.818], [-0.109,  1., -0.421, -0.357], [0.872, -0.421, 1., 0.963], [0.818, -0.357, 0.963,  1.]])\n",
    "#covIris = np.array([[ 0.681, -0.039, 1.265, 0.513], [-0.039, 0.187, -0.32, -0.117], [1.265, -0.32, 3.092, 1.288], [0.513, -0.117,  1.288,  0.579]])\n",
    "arr1 = np.array([A[:,0]])\n",
    "arr2 = np.array(np.array([A[:,0]-1]).T)\n",
    "\n",
    "print(getStats(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110fe3fb9777db4ce1f884af3cc527a40b2c98427ad17781c021ef692bd3d28d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
