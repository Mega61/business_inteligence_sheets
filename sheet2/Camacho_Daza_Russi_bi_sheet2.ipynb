{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 1 (4 points)***\n",
    "1. Under what conditions will the covariance matrix $\\Sigma$ be identical to the correlation matrix? What can you say about the variances of the variables?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random variable results are normalized before being tabulated.\n",
    "- The standard deviation of both variables needs to be 1 on the covariance matrix leading diagonal.\n",
    "- PMFs/PDFs have to display approachable similarity to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Covariances and Correlation after Normalization Techniques. Robustness of Normalization towards linear feature transformations. \n",
    "\n",
    "Let $D \\in R^{n×d}$ be some dataset. Suppose that we have, for each column $X_{j}$,  a transfor-maton $f_{j}:R \\rightarrow R$ that will modify the values in the $j$-th column. The result of applying these functions will be a new dataset (matrix) $\\~{D} \\in R^{nxd}$      with $\\~{D}_{i,j} = f_{j}(D_{i,j})$ Note that we could have $f_{j}(x) = x$ if we do not want to change values in the $j$-th  column.\n",
    "\n",
    "Such  a function $f_{j}$ is  said to be affine if it is of the form $f_{j} = ax+b$  for some $a$, $b$ $\\in R$.\n",
    "\n",
    "a) Give an example for a transformation (may be affine or not) that affects the covariance, i.e., the covariance matrix of $\\~{D}$ is different from that in $D$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f_{j}(x) = 0$ for all $j$. Then $cov(x,y) = 0$ for any two random variable samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now show that $\\^{\\~{\\mu_j}} = a_{j}\\^{\\mu_j} + b_{j}$ and that $\\^{\\~{\\sigma_{i,j}}} = a_{i}a_{j}\\^{\\sigma_{i,j}}$ for any affine transformation $\\^{\\~{\\mu_j}}$, where denotes the empirical mean of attribute $X_{j}$ of $\\~{D}$ and $\\^{\\~{\\sigma_{i,j}}}$ is the empirical covariance of attributes $X_{i}$ and $X_{j}$ in $\\~{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $f_j(x)$ is affine with $f_j(x) = a_j \\cdot x + b_j$.\n",
    "Then:\n",
    "$$\\^{\\~{\\mu_j}} = f_j(\\^{\\mu})$$\n",
    "$$= f_j(E[\\^{\\~{X_j}}])$$\n",
    "$$= E[f_j(\\^{\\~{X_j}})]$$\n",
    "$$= E[a_j \\cdot \\^{X_j} + b_j]$$\n",
    "$$= a_j \\cdot E[\\^{X_j}] + b_j$$\n",
    "$$= a_j \\cdot \\^{\\mu} + b_j$$\n",
    "We also have:\n",
    "$$\\^{\\~{\\sigma_{ij}}} = E[(\\^{\\~{X_i}}-\\^{\\~{\\mu}})(\\^{\\~{X_j}}-\\^{\\~{\\mu}})]$$\n",
    "$$= E[\\^{\\~{X_i}} \\cdot \\^{\\~{X_j}}] - E[\\^{\\~{\\mu_i}}] \\cdot E[\\^{\\~{\\mu_j}}]$$\n",
    "$$= E[(a_i \\cdot \\^{X_i} + b_i)(a_j \\cdot \\^{X_j} + b_j)] - E[a_i \\cdot \\^{\\mu_i} + b_i] \\cdot E[a_j \\cdot \\^{X_j} + b_j]$$\n",
    "$$= E[a_i \\cdot a_j \\cdot \\^{X_i} \\cdot \\^{X_j} + a_i \\cdot \\^{X_i} \\cdot b_j + a_j \\cdot \\^{X_j} \\cdot b_i + b_i \\cdot b_j] - (a_i \\cdot E[\\^{\\mu_i}] + b_i) \\cdot (a_j \\cdot E[\\^{\\mu_j}] + b_j)$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] + a_i \\cdot E[\\^{X_i}] \\cdot b_j + a_j \\cdot E[\\^{X_j}] \\cdot b_i + b_i \\cdot b_j - (a_i \\cdot \\^{\\mu_i} + b_i) \\cdot (a_j \\cdot \\^{mu_j} + b_j)$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] + a_i \\cdot E[\\^{X_i}] \\cdot b_j + a_j \\cdot E[\\^{X_j}] \\cdot b_i + b_i \\cdot b_j - a_i \\cdot \\^{\\mu_i}\\cdot b_j - a_j \\cdot \\^{\\mu_j} \\cdot b_i - b_i \\cdot b_j - a_i \\cdot a_j \\cdot \\^{\\mu_i} \\cdot \\^{\\mu_j}$$\n",
    "$$= a_i \\cdot a_j \\cdot E[\\^{X_i} \\cdot \\^{X_j}] - a_i \\cdot a_j \\cdot \\^{\\mu_i} \\cdot \\^{\\mu_j}$$\n",
    "$$= a_i \\cdot a_j (E[\\^{X_i} \\cdot \\^{X_j}] - \\^{\\mu_i} \\cdot \\^{\\mu_j})$$\n",
    "$$= a_i \\cdot a_j \\cdot \\^{\\sigma_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Now let $\\^{\\~{\\rho_{i,j}}}$ be the correlation between $X_{i}$ and $X_{j}$ in $D$. Show that $\\^{\\~{\\rho_{i,j}}} = \\^{\\rho_{i,j}}$. State in your own words what this property means (one sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "$$\\^{\\~{\\rho_{12}}} = \\frac{\\^{\\~{\\sigma_{12}}}}{\\^{\\~{\\sigma_1}} \\cdot \\^{\\~{\\sigma_2}}}$$\n",
    "$$= \\frac{\\^{\\~{\\sigma_{12}}}}{\\sqrt{\\^{\\~{\\sigma_1^2}} \\cdot \\^{\\~{\\sigma_2^2}}}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{\\sqrt{(a_i^2 \\cdot \\^{\\sigma_1^2}) \\cdot (a_j^2 \\cdot \\^{\\sigma_2^2})}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{\\sqrt{a_i^2 \\cdot a_j^2 \\cdot \\^{\\sigma_1^2} \\cdot \\^{\\sigma_2^2}}}$$\n",
    "$$= \\frac{a_i \\cdot a_j \\cdot \\^{\\sigma_{12}}}{a_i \\cdot a_j \\sqrt{\\^{\\sigma_1^2 \\cdot \\sigma_2^2}}}$$\n",
    "$$= \\frac{\\^{\\sigma_{12}}}{\\sqrt{\\^{\\sigma_1^2 \\cdot \\sigma_2^2}}}$$\n",
    "$$= \\frac{\\^{\\sigma_{12}}}{\\^{\\sigma_1} \\cdot \\^{\\sigma_2}}$$\n",
    "$$= \\^{\\rho_{12}}$$\n",
    "\n",
    "This means that when any affine function is applied to a set of columns from a matrix, its covariance matrix will not change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2 (4 Points)***\n",
    "\n",
    "Use only one notebook for the following exercises. Answer the ques-tions in separate markdowncells under the corresponding code. \n",
    "\n",
    "Do notuse any lirbary’s function to compute the mean, cov or cor (like np.cov) within thisexercise.\n",
    "\n",
    "Make sure that your functions have exactly the required name (in order to make them appli-cable to unit tests).\n",
    "\n",
    "1. Write a function getStats(A) that outputs (i) the sample mean, the sample covariance matrix, and (iii) the correlation matrix for a given 2-dimensional numpy arrayA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5.843, 3.054, 3.759, 1.199]), array([[ 0.681, -0.039,  1.265,  0.513, -0.039,  0.187, -0.32 , -0.117,\n",
      "         1.265, -0.32 ,  3.092,  1.288,  0.513, -0.117,  1.288,  0.579]]), array([[ 1.   , -0.109,  0.872,  0.818, -0.109,  1.   , -0.421, -0.357,\n",
      "         0.872, -0.421,  1.   ,  0.963,  0.818, -0.357,  0.963,  1.   ]]))\n"
     ]
    }
   ],
   "source": [
    "from statistics import correlation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "dfIrisTest = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A = dfIrisTest.values[:, 0:4].astype(float)\n",
    "\n",
    "def getStats(A):\n",
    "    vector_sample_mean = []\n",
    "    vector_covariance = np.array([[]])\n",
    "    vector_correlation = np.array([[]])\n",
    "    list_cov = np.array([[]])\n",
    "    list_corr = np.array([[]])\n",
    "    \n",
    "    # Calculate the Sample Mean\n",
    "    for j in range(np.size(A, 1)):\n",
    "        sample_mean = 0\n",
    "        for i in range(np.size(A, 0)):\n",
    "            sample_mean += A[i, j]/np.size(A, 0)\n",
    "        vector_sample_mean += [sample_mean]\n",
    "\n",
    "    #Calculate the Sample Covariance Matrix\n",
    "    for j in range (len(vector_sample_mean)):\n",
    "        list_cov = np.array([[]])\n",
    "        for i in range (len(vector_sample_mean)):\n",
    "            cov1 = np.array([A[:,j]-vector_sample_mean[j]])\n",
    "            cov2 = (np.array([A[:,i]-vector_sample_mean[i]]))\n",
    "            covariance = ((np.dot(cov2, cov1.T)))/len(A[:, i])\n",
    "            list_cov = np.column_stack([list_cov, covariance])\n",
    "        vector_covariance =  np.column_stack([vector_covariance, list_cov])\n",
    "        \n",
    "    #Calculate the Correlation Matrix\n",
    "    for j in range (len(vector_sample_mean)):\n",
    "        list_corr = np.array([[]])\n",
    "        for i in range (len(vector_sample_mean)):\n",
    "            corr1 = np.array([A[:,j]-vector_sample_mean[j]])\n",
    "            corr2 = np.array([A[:,i]-vector_sample_mean[i]])\n",
    "            sqrt1 = np.sqrt((np.dot(corr1, corr1.T)))\n",
    "            sqrt2 = np.sqrt((np.dot(corr2, corr2.T)))\n",
    "            correlation = ((np.dot(corr2, corr1.T)))/(np.dot(sqrt1, sqrt2))\n",
    "            list_corr = np.column_stack([list_corr, correlation])\n",
    "        vector_correlation =  np.column_stack([vector_correlation, list_corr])\n",
    " \n",
    "    return np.round(vector_sample_mean,3), np.round(vector_covariance, 3), np.round(vector_correlation, 3)\n",
    "\n",
    "#np.array([[ 1., -0.109, 0.872, 0.818], [-0.109,  1., -0.421, -0.357], [0.872, -0.421, 1., 0.963], [0.818, -0.357, 0.963,  1.]])\n",
    "#covIris = np.array([[ 0.681, -0.039, 1.265, 0.513], [-0.039, 0.187, -0.32, -0.117], [1.265, -0.32, 3.092, 1.288], [0.513, -0.117,  1.288,  0.579]])\n",
    "arr1 = np.array([A[:,0]])\n",
    "arr2 = np.array(np.array([A[:,0]-1]).T)\n",
    "\n",
    "print(getStats(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56d6b7505314121711e9f0b42f9bc62740a6380b1f361bd988b93b9c1b16c56f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
